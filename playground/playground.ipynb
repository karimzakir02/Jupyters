{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground\n",
    "\n",
    "This notebook contains notes and examples of some of the different machine learning concepts I encounter when learning. Essentially, this is a space for me to keep them for future use, as well as try them in practice. This kind of practice and note-taking also helps me remember the methods and understand them better. Hope you learn something from this as well!\n",
    "\n",
    "Please note that this notebook **doesn't** reflect everything I know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# General helper functions:\n",
    "def score_model(model, X_train, y_train, X_test, y_test, accuracy_call):\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    return accuracy_call(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "This section contains some of the methods which help pick features and understand their importance in predicting the target variable.\n",
    "\n",
    "### Mutual Information\n",
    "Mutual information (MI) is a great general-purpose metric and is especially useful at the start when you might not know what model you would like to use. MI between two quantities measures the extent to which knowledge about one quantity reduces uncertainity about the other. Uncertainty is measured using a quantity from information theory known as 'entropy'. The entropy of a variable roughly means: \"how many yes or no questions you would need to describe an occurrence of that variable, on average\". The more questions you have to ask, the more uncertain you are about the variable. Mutual information is how many questions you expect the feature to answer about the target. Least possible score is 0.0. In theory, there is no limit; in practice, it is rare to get a value about 2.0. MI is logarithmic, so its rate of increase is slow. \n",
    "\n",
    "| Pros | Cons |\n",
    "| ---- | ---- |\n",
    "| Easy to use and interpret | Univariate (can't detect interactions between features) |\n",
    "| Computationally efficient | Actual usefulnes still depends on the model. May need to transform a feature, as a result |\n",
    "| Theoretically well-founded | |\n",
    "| Resistant to overfitting | |\n",
    "| Can detect any kind of relationship | |\n",
    "\n",
    "Scikit-learn's implementation of MI treats discrete and continous variables differently. So, when using their implementation, make sure to specify which variables are discrete. This is done by passing a list argument in the `discrete` parameter of the function.\n",
    "\n",
    "Source: [Kaggle](https://www.kaggle.com/ryanholbrook/mutual-information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluminium</th>\n",
       "      <th>ammonia</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>barium</th>\n",
       "      <th>cadmium</th>\n",
       "      <th>chloramine</th>\n",
       "      <th>chromium</th>\n",
       "      <th>copper</th>\n",
       "      <th>flouride</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>...</th>\n",
       "      <th>lead</th>\n",
       "      <th>nitrates</th>\n",
       "      <th>nitrites</th>\n",
       "      <th>mercury</th>\n",
       "      <th>perchlorate</th>\n",
       "      <th>radium</th>\n",
       "      <th>selenium</th>\n",
       "      <th>silver</th>\n",
       "      <th>uranium</th>\n",
       "      <th>is_safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.65</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>16.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.007</td>\n",
       "      <td>37.75</td>\n",
       "      <td>6.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.32</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.002</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.003</td>\n",
       "      <td>32.26</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.01</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.008</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.006</td>\n",
       "      <td>50.28</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.36</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.004</td>\n",
       "      <td>9.12</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.92</td>\n",
       "      <td>24.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.003</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aluminium  ammonia  arsenic  barium  cadmium  chloramine  chromium  copper  \\\n",
       "0       1.65     9.08     0.04    2.85    0.007        0.35      0.83    0.17   \n",
       "1       2.32    21.16     0.01    3.31    0.002        5.28      0.68    0.66   \n",
       "2       1.01    14.02     0.04    0.58    0.008        4.24      0.53    0.02   \n",
       "3       1.36    11.33     0.04    2.96    0.001        7.23      0.03    1.66   \n",
       "4       0.92    24.33     0.03    0.20    0.006        2.67      0.69    0.57   \n",
       "\n",
       "   flouride  bacteria  ...   lead  nitrates  nitrites  mercury  perchlorate  \\\n",
       "0      0.05      0.20  ...  0.054     16.08      1.13    0.007        37.75   \n",
       "1      0.90      0.65  ...  0.100      2.01      1.93    0.003        32.26   \n",
       "2      0.99      0.05  ...  0.078     14.16      1.11    0.006        50.28   \n",
       "3      1.08      0.71  ...  0.016      1.41      1.29    0.004         9.12   \n",
       "4      0.61      0.13  ...  0.117      6.74      1.11    0.003        16.90   \n",
       "\n",
       "   radium  selenium  silver  uranium  is_safe  \n",
       "0    6.78      0.08    0.34     0.02        1  \n",
       "1    3.21      0.08    0.27     0.05        1  \n",
       "2    7.07      0.07    0.44     0.01        0  \n",
       "3    1.72      0.02    0.45     0.05        1  \n",
       "4    2.41      0.02    0.06     0.02        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_df = pd.read_csv(\"datasets/water_quality.csv\")\n",
    "water_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = water_df.copy()\n",
    "y = X.pop(\"is_safe\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:27:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBClassifier(), X_train, y_train, X_test, y_test, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = mutual_info_classif(X, y, random_state=0)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Score\", index=X.columns)\n",
    "mi_scores.sort_values(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = np.arange(len(mi_scores))\n",
    "ticks = list(mi_scores.index)\n",
    "plt.barh(width, mi_scores)\n",
    "plt.yticks(width, ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='is_safe', ylabel='cadmium'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"is_safe\", y=\"cadmium\", data=water_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='is_safe', ylabel='ammonia'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"is_safe\", y=\"ammonia\", data=water_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ammonia may still be an interaction variable (valuable in combination with another variable), so it is good to investigate this during actual analysis. This may also be the case for all of the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = mi_scores[mi_scores > 0].index.values.tolist()\n",
    "X_train_1 = X_train[new_features]\n",
    "X_test_1 = X_test[new_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:00:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = XGBClassifier()\n",
    "score_model(new_model, X_train_1, y_train, X_test_1, y_test, accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance worsened, shows that there is interaction within the variables that we got rid of.\n",
    "\n",
    "If the target variable is continious, use `mutual_info_regression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square Test\n",
    "The Chi-Square Test is a statistical test which is used to test the independence of two events/variables. In feature selection, the test is only used with categorical targets. Like other statistical tests, we establish a null hypothesis and an alternative hypothesis. The higher is the Chi-Square value, the higher is the dependence of a variable on another variable. Another important value we get with the test is the p-value. Similarly to other statistical tests, it suggests how statistically significant the results are. \n",
    "\n",
    "There are two ways of feature selection using this method. The first method is selecting the top n features with the highest Chi-Square value. This method works best if you know how many features you would like to have in your model. Another method is to use the resulting p-values in order to determine whether the column is statistically significant or not. As usual, pick an alpha value and compare it to the p-value.\n",
    "\n",
    "| Pros | Cons |\n",
    "| ---- | ---- |\n",
    "| Relatively easy to use | Only works on categorical target variables|\n",
    "| Two easy methods for feature selection | Gets complicated with highly cardinal categorical features | \n",
    "| Theoretically well-founded | In case of categorical features, need to make sure each category has more than 5 values |\n",
    "| Makes no assumptions about the distribution of the data | | \n",
    "\n",
    "\n",
    "Sources: [Medium](https://towardsdatascience.com/categorical-feature-selection-via-chi-square-fc558b09de43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LP001003</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP001005</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP001006</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP001008</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LP001011</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Gender Married Dependents     Education Self_Employed  \\\n",
       "Loan_ID                                                          \n",
       "LP001003   Male     Yes          1      Graduate            No   \n",
       "LP001005   Male     Yes          0      Graduate           Yes   \n",
       "LP001006   Male     Yes          0  Not Graduate            No   \n",
       "LP001008   Male      No          0      Graduate            No   \n",
       "LP001011   Male     Yes          2      Graduate           Yes   \n",
       "\n",
       "          ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "Loan_ID                                                                      \n",
       "LP001003             4583             1508.0       128.0             360.0   \n",
       "LP001005             3000                0.0        66.0             360.0   \n",
       "LP001006             2583             2358.0       120.0             360.0   \n",
       "LP001008             6000                0.0       141.0             360.0   \n",
       "LP001011             5417             4196.0       267.0             360.0   \n",
       "\n",
       "          Credit_History Property_Area Loan_Status  \n",
       "Loan_ID                                             \n",
       "LP001003             1.0         Rural           N  \n",
       "LP001005             1.0         Urban           Y  \n",
       "LP001006             1.0         Urban           Y  \n",
       "LP001008             1.0         Urban           Y  \n",
       "LP001011             1.0         Urban           Y  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans = pd.read_csv(\"datasets/loan_data_set.csv\", index_col=0)\n",
    "loans.dropna(inplace=True)\n",
    "loans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loans.copy()\n",
    "y = X.pop(\"Loan_Status\")\n",
    "X[\"Gender\"] = (X[\"Gender\"] == \"Male\").astype(int)\n",
    "X[\"Married\"] = (X[\"Married\"] == \"Yes\").astype(int)\n",
    "y = (y == \"Y\").astype(int)\n",
    "X.drop([\"Education\", \"Self_Employed\", \"Property_Area\", \"Dependents\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:06:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7083333333333334"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBClassifier(), X_train, y_train, X_test, y_test, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_values, p_values = chi2(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoapplicantIncome    11874.263112\n",
       "ApplicantIncome        278.106943\n",
       "LoanAmount              25.039383\n",
       "Credit_History          16.256902\n",
       "Loan_Amount_Term         4.663135\n",
       "Married                  2.748794\n",
       "Gender                   0.337003\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_series = pd.Series(chi2_values, index=X.columns)\n",
    "chi2_series.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender               5.615645e-01\n",
       "Married              9.732780e-02\n",
       "ApplicantIncome      1.941471e-62\n",
       "CoapplicantIncome    0.000000e+00\n",
       "LoanAmount           5.617121e-07\n",
       "Loan_Amount_Term     3.081688e-02\n",
       "Credit_History       5.530775e-05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_series = pd.Series(p_values, index=X.columns)\n",
    "p_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using p-values in order to determine which columns to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.05\n",
    "new_features = p_series[p_series < ALPHA].index.values.tolist()\n",
    "X_train_1 = X_train[new_features]\n",
    "X_test_1 = X_test[new_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplicantIncome',\n",
       " 'CoapplicantIncome',\n",
       " 'LoanAmount',\n",
       " 'Loan_Amount_Term',\n",
       " 'Credit_History']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:07:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71875"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBClassifier(), X_train_1, y_train, X_test_1, y_test, accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, an improvement!\n",
    "\n",
    "In case you are using the first method for chi-square feature selection (top n features), it is more convinient to use sklearn's built in method `SelectKBest` in the `feature_selection` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_selector = SelectKBest(chi2, k=3)\n",
    "X_2 = chi2_selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = X.columns[chi2_selector.get_support()]  # chi2_selectkr.get_support() gets a mask for the columns/features used\n",
    "X_train_2 = X_train[new_features]\n",
    "X_test_2 = X_test[new_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:08:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5520833333333334"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBClassifier(), X_train_2, y_train, X_test_2, y_test, accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite using top 3 features, the accuracy greatly decreased. Perhaps it is worth increasing the amount of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_selector = SelectKBest(chi2, k=4)\n",
    "X_3 = chi2_selector.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = X.columns[chi2_selector.get_support()]  # chi2_selectkr.get_support() gets a mask for the columns/features used\n",
    "X_train_3 = X_train[new_features]\n",
    "X_test_3 = X_test[new_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:08:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6979166666666666"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBClassifier(), X_train_3, y_train, X_test_3, y_test, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Credit_History'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance increased drastically, but we still obtained a better result when we used the p-value method. I think when the amount of features is small, it makes more sense to use the p-value method; however, if there are thousands of features, it is better to instead use the SelectKBest method, because that will narrow down the amount of features, which will save time when training and testing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation\n",
    "\n",
    "This section contains some techniques used in order to create new features based on old features.\n",
    "\n",
    "### Principal Component Analysis\n",
    "\n",
    "Principal Component Analysis (PCA) is an unsupervised learning technique used to surface the core patterns in the data. It creates new features by taking existing features and creating linear combinations of them. These new linear combinations are called principal components of the data. There will be as many principal components as there are features in the linear combinations. The weights used for the linear combinations are called loadings. They tell us what variation it expresses through its signs and magnitudes. PCA also tells us the amount of variation in each component. PCA makes this precise through each component's percent of explained variance. But there isn't necessarily a correlation between amount of variance explained and how useful of a feature it is. It is still good to use something like MI. \n",
    "\n",
    "The goal of Principal Component Analysis is to apply linear transformations to the data in order to minimize noise and redundancy. The result will reveal the most iportant characteristics about the data. After applying PCA, you'll have a set of principal components ranked according to how much variance they explain or how much they contribute to describing patterns in the data. PCA uses the covariance matrix to analyze the variance of each feature (relevant or pure noise), and the strength of linear relationships between pairs of features (helps to spot redundant features). \n",
    "\n",
    "There won't be a one-to-one relationship between features and principal components (most of the time). This is good, because it means that the principal component **encoded** the variation of only specific features and shows how those particular features interact with each other. That's the beauty of principal component analysis. Additionally, say we were able to encode the variation of 10 features in a single principal component analysis, that means that we were able to capture the information from 10 features into a single feature/component. This is a complex topic called [Factor Analysis](https://en.wikipedia.org/wiki/Factor_analysis). Need to look into it later. Although it's not always best to use only principal components, that's still really cool. Note that correlation and the loadings for each feature-pca pair will not necessarily be the same, will be different most-likely. \n",
    "\n",
    "There are two approaches to identify the principal components:\n",
    "1. Calculate the eigenvectors of the covariance matrix.\n",
    "2. Calculate the Singular Value Decomposition (SVD)\n",
    "\n",
    "`scikit-learn` only has SVD in its implementation, while a library like `statsmodels` has both the eigenvectors approach and the SVD.\n",
    "\n",
    "There are two ways to use PCA for feature engineering:\n",
    "\n",
    "1. Use it as a descriptive techniques. Since the component tells you about variation, you could compute the MI scores for the components and see what kind of variation is most predictive of the target. That could give you ideas, which features to multiply, or divide, etc. Could even try clustering on one or more of the high-scoring components. \n",
    "2. Use components themselves as features. Can often be more informative than the original features. Especially useful when:\n",
    "- The features are highly redundant (multicollinear), PCA will partition out the redundancy into one or more near-zero variance components. It does this by minimizing the covariance between pairs of features. \n",
    "- There's a lot of noise in the data. PCA will collect the signals and leave the noise, boosting the signal-to-noise ratio\n",
    "- There're highly-correlated features, and your ML algorithm doesn't work well with them. PCA transforms correlated features into uncorrelated components, which could be easier for certain alogorithms to work with. \n",
    "\n",
    "Best practices:\n",
    "- Only works with numeric features, like continious quantities or counts\n",
    "- PCA is sensetive to scale, so it's good practice to standardize the data, unless there's a good reason not to. This will make principal components linearly independent, as well as orthogonal (principal components will make a 90 degree angle with each other). \n",
    "- Remove or constrain outliers, since they can have an undue influence on the results. \n",
    "\n",
    "The trade-off with using PCA and not the actual features is interpretability. When plotting features against each other, it's easier to interpret the patterns. Since principal components encode several features, it's not clear what features each principal component encodes, and what proportion of each feature has more impact on the patterns we are seeing. \n",
    "\n",
    "Methods to pick which PCA's should replace actual features:\n",
    "1. Kaiser Criterion\n",
    "\n",
    "    With this criterion, pick only the principal components that have eigenvalues greater than 1. Each eigenvalue is associated with a single eigenvector, which is a principal component. \n",
    "    \n",
    "2. Explained variance\n",
    "    \n",
    "    With this method, you pick the total amount of variance in the dataset you want the components to encode. Usually, these cut-off values are 80% or 90%. So for instance, the cumilative explained variance will be 80% for the first 6 components, so you only use the first 6 components. Depends on the cut-off you establish, though. \n",
    "    \n",
    "3. Scree plot\n",
    "    \n",
    "    With this method, we pick the components in a more visual way. We plot the eigenvalue for each component and use the elbow method to determine the cut-off point. The idea is to see where the \"elbow\" is for the plot and make that the cut-off point. It is a less precise method since it is much more visual and seems more subjective. \n",
    "    \n",
    "Sources: [Kaggle](https://www.kaggle.com/ryanholbrook/principal-component-analysis), [Medium Article](https://towardsdatascience.com/principal-component-analysis-algorithm-in-real-life-discovering-patterns-in-a-real-estate-dataset-18134c57ffe7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.multivariate.pca import PCA as sm_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv(\"datasets/houses_to_rent_v2.csv\")\n",
    "features = [\"area\", \"rooms\", \"bathroom\", \"parking spaces\"]\n",
    "X = (houses[features] - houses[features].mean(axis=0)) / houses[features].std(axis=0) # z-score normalization\n",
    "y = houses[\"total (R$)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2189.371605201211"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBRegressor(), X_train, y_train, X_test, y_test, mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.fit_transform(X_train)\n",
    "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "X_pca = pd.DataFrame(X_pca, columns=component_names, index=X_train.index)\n",
    "loadings = pd.DataFrame(pca.components_.T,  columns=component_names, index=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = mutual_info_regression(X_pca, y_train, random_state=0)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Score\", index=X_pca.columns)\n",
    "mi_scores.sort_values(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = np.arange(len(mi_scores))\n",
    "ticks = list(mi_scores.index)\n",
    "plt.barh(width, mi_scores)\n",
    "plt.yticks(width, ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train.merge(X_pca, left_index=True, right_index=True)\n",
    "X_test_1 = X_test.copy()\n",
    "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "X_test_pca = pd.DataFrame(pca.transform(X_test_1), columns=component_names, index=X_test_1.index)\n",
    "X_test_1 = X_test_1.merge(X_test_pca, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2201.2308240607836"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBRegressor(), X_train_1, y_train, X_test_1, y_test, mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance has worsened! Let's try the second method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <td>0.129898</td>\n",
       "      <td>-0.002398</td>\n",
       "      <td>0.028373</td>\n",
       "      <td>0.991118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>0.572568</td>\n",
       "      <td>0.642498</td>\n",
       "      <td>-0.505847</td>\n",
       "      <td>-0.059006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathroom</th>\n",
       "      <td>0.586195</td>\n",
       "      <td>0.096894</td>\n",
       "      <td>0.798184</td>\n",
       "      <td>-0.099443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parking spaces</th>\n",
       "      <td>0.558272</td>\n",
       "      <td>-0.760133</td>\n",
       "      <td>-0.325909</td>\n",
       "      <td>-0.065678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PC1       PC2       PC3       PC4\n",
       "area            0.129898 -0.002398  0.028373  0.991118\n",
       "rooms           0.572568  0.642498 -0.505847 -0.059006\n",
       "bathroom        0.586195  0.096894  0.798184 -0.099443\n",
       "parking spaces  0.558272 -0.760133 -0.325909 -0.065678"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.copy()\n",
    "X_test_2 = X_test.copy()\n",
    "X_train_2[\"rooms_parking_spaces_interaction\"] = X_train_2[\"rooms\"] / X_train_2[\"parking spaces\"]\n",
    "X_train_2[\"rooms_bathroom_interaction\"] = X_train_2[\"rooms\"] / X_train_2[\"bathroom\"]\n",
    "X_test_2[\"rooms_parking_spaces_interaction\"] = X_test_2[\"rooms\"] / X_test_2[\"parking spaces\"]\n",
    "X_test_2[\"rooms_bathroom_interaction\"] = X_test_2[\"rooms\"] / X_test_2[\"bathroom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2210.1870969225724"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBRegressor(), X_train_2, y_train, X_test_2, y_test, mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance worsened by a decent amount. But this doesn't indicate that this isn't a good idea. Perhaps, this is the case for this specific dataset. Maybe we should also try using the `statsmodels` implementation, since the use of eigenvectors instead of SVD may help the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sm_pca(X_train, standardize=True, method=\"eig\")\n",
    "X_pca_sm = pd.DataFrame(pca.transformed_data, columns=component_names, index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.merge(X_pca_sm, left_index=True, right_index=True)\n",
    "X_test_2 = X_test.copy()\n",
    "loadings = pca.loadings.transpose().values.tolist()\n",
    "for index, loadings in enumerate(loadings):\n",
    "    X_test_2[f\"PC{index+1}\"] = X_test_2[\"area\"] * loadings[0] + X_test_2[\"rooms\"] * loadings[1] + \\\n",
    "                                X_test_2[\"bathroom\"] * loadings[2] + X_test_2[\"parking spaces\"] * loadings[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2189.371605201211"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBRegressor(), X_train_2, y_train, X_test_2, y_test, mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exact same result as with the default model. Perhaps, this suggests that the principal components perfectly captured the variance present in the default variables. It's still a bit weird that it's so perfect, so I'll need to double check later. Let's now try out the three methods of component selection.\n",
    "\n",
    "Kaiser Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26354.375085\n",
       "1     3301.911874\n",
       "2     2505.344826\n",
       "3     2050.368215\n",
       "Name: eigenvals, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.eigenvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All components have an eigenvalue greater than 1, so they should all be used in the model.\n",
    "\n",
    "Explained Variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.77032547, 0.86683874, 0.94006874, 1.        ])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.rsquare.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set the threshold to 80%, it would be enough to just use the first two components. A lot of variance is explained in the first two components.\n",
    "\n",
    "Scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca.plot_scree()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elbow seems to be at the second component (1.0 mark), so it would make sense to only use the first two components using this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding\n",
    "\n",
    "Targer encoding replaces a category from a categorical feature with some number derived from the target, an aggregate value. This, however, presents certain problems. Firstly, certain categories that can appear in production or testing data can be not present in the training dataset. Secondly, when a category appears a few times within the feature, any statistics calculated based on the category is unlikely to be accurate, making overfitting more likely. A solution to this is to add smoothing. The idea is to blend-in the category average with the overall average. Rare categories get less weight on their category average, while missing categories just get the overall average. \n",
    "\n",
    "In pseudocode:\n",
    "\n",
    "`encoding = weight * in_category_average + (1 - weight) * overall_average`, where `weight` is a value between 0 and 1 calculated from category frequency. An easy way to calcualate the weight is by using an m-estimate:\n",
    "\n",
    "`weight = n / (n+m)`, where `n` is the total number of times a category appears in the feature, and `m` is the \"smoothing factor\". \n",
    "\n",
    "Larger values of `m` put more weight on the overall estimate. When choosing a value for `m`, consider how noisy you expect the categories to be. Does the target value vary greatly within the category? Would you need a lot of data to get good estimates? If so, pick a high value for `m`. \n",
    "\n",
    "This is great for:\n",
    "- High-cardinality features (a lot of categories)\n",
    "- Domain-driven features. You might suspect that a categorical feature should be important even if it scored poorly with a feature metric. A target encoding can help reveal a feature's true informativeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/houses_to_rent_v2.csv\")\n",
    "features = [\"city\", \"area\", \"rooms\", \"bathroom\", \"parking spaces\"]\n",
    "X = df[features]\n",
    "y = df[\"total (R$)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_X_train = X_train.copy()\n",
    "old_y_train = y_train.copy()\n",
    "old_X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encode = X_train.sample(frac=0.25, random_state=0)\n",
    "y_encode = y_train[X_encode.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(X_encode.index, inplace=True)\n",
    "y_train.drop(X_encode.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MEstimateEncoder(cols=[\"city\"], m=1.0)\n",
    "encoder.fit(X_encode, y_encode)\n",
    "X_train = encoder.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>3051.740514</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>6309.699087</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>6309.699087</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>2776.704732</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3051.740514</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>2776.704732</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9225</th>\n",
       "      <td>5091.425623</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>6309.699087</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>5091.425623</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>6309.699087</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6415 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             city  area  rooms  bathroom  parking spaces\n",
       "3083  3051.740514    70      1         1               2\n",
       "508   6309.699087    40      1         1               1\n",
       "3079  6309.699087   113      3         4               3\n",
       "2036  2776.704732    40      2         1               1\n",
       "49    3051.740514    48      1         1               1\n",
       "...           ...   ...    ...       ...             ...\n",
       "7891  2776.704732    50      1         1               1\n",
       "9225  5091.425623    90      3         2               1\n",
       "4859  6309.699087   240      3         4               3\n",
       "3264  5091.425623   106      2         2               1\n",
       "9845  6309.699087   140      1         2               2\n",
       "\n",
       "[6415 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = mutual_info_regression(X_train, y_train, random_state=0)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Score\", index=X.columns)\n",
    "mi_scores.sort_values(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city              0.110187\n",
       "rooms             0.301099\n",
       "parking spaces    0.322353\n",
       "bathroom          0.401508\n",
       "area              0.527688\n",
       "Name: MI Score, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the most useful feature, but still decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2213.5174530871063"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_features = [\"rooms\", \"parking spaces\", \"bathroom\", \"area\"]\n",
    "score_model(XGBRegressor(), X_train[old_features], y_train, X_test[old_features], y_test, mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>3051.740514</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>6309.699087</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>6309.699087</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>2776.704732</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3051.740514</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7891</th>\n",
       "      <td>2776.704732</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9225</th>\n",
       "      <td>5091.425623</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>6309.699087</td>\n",
       "      <td>240</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>5091.425623</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>6309.699087</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6415 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             city  area  rooms  bathroom  parking spaces\n",
       "3083  3051.740514    70      1         1               2\n",
       "508   6309.699087    40      1         1               1\n",
       "3079  6309.699087   113      3         4               3\n",
       "2036  2776.704732    40      2         1               1\n",
       "49    3051.740514    48      1         1               1\n",
       "...           ...   ...    ...       ...             ...\n",
       "7891  2776.704732    50      1         1               1\n",
       "9225  5091.425623    90      3         2               1\n",
       "4859  6309.699087   240      3         4               3\n",
       "3264  5091.425623   106      2         2               1\n",
       "9845  6309.699087   140      1         2               2\n",
       "\n",
       "[6415 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2062.925920669249"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features = [\"city\", \"rooms\", \"parking spaces\", \"bathroom\", \"area\"]\n",
    "score_model(XGBRegressor(), X_train[new_features], y_train, X_test[new_features], y_test, mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "oh_cols_train = pd.DataFrame(oh_encoder.fit_transform(old_X_train[[\"city\"]]))\n",
    "oh_cols_test = pd.DataFrame(oh_encoder.transform(old_X_test[[\"city\"]]))\n",
    "oh_cols_train.index = old_X_train.index\n",
    "oh_cols_test.index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_X_train.drop(\"city\", axis=1, inplace=True)\n",
    "old_X_test.drop(\"city\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_X_train = old_X_train.merge(oh_cols_train, left_index=True, right_index=True)\n",
    "old_X_test = old_X_test.merge(oh_cols_test, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2079.358791699082"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(XGBRegressor(), old_X_train, old_y_train, old_X_test, y_test, mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our accuracy was higher using target encoding, we can say that the extra information gained using target encoding made up for the loss of data used for the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization\n",
    "\n",
    "Discretization is the process through which we transform continious variables, models, or functions into a discrete form. We do this by creating a set of contiguous intervals (bins) that go across the range of our desire variable/model/function. Why use it?\n",
    "\n",
    "1. **It fits the problem statement.** It is often easier to understand continious data (such as height) when divided and stored into meaningful groups or categories. We can divide height into the following groups: under 1.5m (short), 1.5-1.85 (medium height), 1.85+ (tall). We would consider the structure useful if we see no objective difference between variables falling under the same height class. 1.6m and 1.7m convey the same information (medium height). Discretization helps make our dataset easier to understand if it fits the problem statement.\n",
    "2. **Interprets features.** Continious features have a smaller chance of correlating with the target variable due to infinite degrees of freedom and may have complex non-linear relationships. Thus, it may be harder to interpret such feature. After discretizing, groups corresponding to the target can be interpreted. \n",
    "3. **Incompatible with models/methods.** Certain models may not work well with continious features, such as a Random Forest Model, which works best with discrete features. Feature engineering methods, for example any entropy-based methods may not work with continious data, thus we would discretize variables to work with different models & methods. \n",
    "4. **Signal-to-noise ratio.** When we discretize a model, we are fitting it to bins and reducing the impact of small fluctuation in the data, which can be considered as noise. We can reduce this noise through discretization. Discretization smoothes the data, since each bin smoothes the fluctuations, reducing the noise in the data.\n",
    "\n",
    "There are several different techniques of feature discretization:\n",
    "\n",
    "- Supervised:\n",
    "    1. Equal Width\n",
    "    2. Equal Frequency\n",
    "    3. K-Means\n",
    "- Unsupervised:\n",
    "    1. Decision Trees\n",
    "\n",
    "\n",
    "Source: [Medium](https://towardsdatascience.com/an-introduction-to-discretization-in-data-science-55ef8c9775a2)\n",
    "\n",
    "Equal Width:\n",
    "\n",
    "Separates all possible values into `n` number of bins, each having the same width. To calculate interval width: `width = (max_value - min_value) / n`. \n",
    "\n",
    "- Can handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart = pd.read_csv(\"datasets/walmart_sales_data.csv\")\n",
    "temperature = walmart[[\"Temperature\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_width_disc = KBinsDiscretizer(n_bins=3, encode=\"onehot\", strategy=\"uniform\")\n",
    "equal_width_transformed = equal_width_disc.fit_transform(temperature).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"low_temp\", \"medium_temp\", \"high_temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_width_dataframe = pd.DataFrame(equal_width_transformed, columns=columns, index=temperature.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low_temp</th>\n",
       "      <th>medium_temp</th>\n",
       "      <th>high_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6435 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      low_temp  medium_temp  high_temp\n",
       "0          0.0          1.0        0.0\n",
       "1          0.0          1.0        0.0\n",
       "2          0.0          1.0        0.0\n",
       "3          0.0          1.0        0.0\n",
       "4          0.0          1.0        0.0\n",
       "...        ...          ...        ...\n",
       "6430       0.0          1.0        0.0\n",
       "6431       0.0          1.0        0.0\n",
       "6432       0.0          1.0        0.0\n",
       "6433       0.0          1.0        0.0\n",
       "6434       0.0          1.0        0.0\n",
       "\n",
       "[6435 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_width_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_width_disc.n_bins_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ -2.06      ,  32.00666667,  66.07333333, 100.14      ])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_width_disc.bin_edges_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equal Frequency:\n",
    "\n",
    "Separates all values into `n` number of bins, each with the same amount of observations. May correspond to quantile values as well.\n",
    "\n",
    "- Improves value spread\n",
    "- Can handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_freq_disc = KBinsDiscretizer(n_bins=3, encode=\"onehot\", strategy=\"quantile\")\n",
    "equal_freq_transformed = equal_freq_disc.fit_transform(temperature).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_freq_dataframe = pd.DataFrame(equal_freq_transformed, columns=columns, index=temperature.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low_temp</th>\n",
       "      <th>medium_temp</th>\n",
       "      <th>high_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6435 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      low_temp  medium_temp  high_temp\n",
       "0          1.0          0.0        0.0\n",
       "1          1.0          0.0        0.0\n",
       "2          1.0          0.0        0.0\n",
       "3          1.0          0.0        0.0\n",
       "4          1.0          0.0        0.0\n",
       "...        ...          ...        ...\n",
       "6430       0.0          1.0        0.0\n",
       "6431       0.0          1.0        0.0\n",
       "6432       0.0          1.0        0.0\n",
       "6433       0.0          1.0        0.0\n",
       "6434       0.0          1.0        0.0\n",
       "\n",
       "[6435 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_freq_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ -2.06,  52.54,  70.71, 100.14])], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_freq_disc.bin_edges_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiet different values and bin edges. \n",
    "\n",
    "K-Means Clustering:\n",
    "Separates observations using the K-Means clustering algorithm. \n",
    "\n",
    "- Can handle outliers, but a centroid bias may exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_disc = KBinsDiscretizer(n_bins=3, encode=\"onehot\", strategy=\"kmeans\")\n",
    "k_means_transformed = k_means_disc.fit_transform(temperature).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_dataframe = pd.DataFrame(k_means_transformed, columns=columns, index=temperature.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low_temp</th>\n",
       "      <th>medium_temp</th>\n",
       "      <th>high_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6435 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      low_temp  medium_temp  high_temp\n",
       "0          1.0          0.0        0.0\n",
       "1          1.0          0.0        0.0\n",
       "2          1.0          0.0        0.0\n",
       "3          0.0          1.0        0.0\n",
       "4          0.0          1.0        0.0\n",
       "...        ...          ...        ...\n",
       "6430       0.0          1.0        0.0\n",
       "6431       0.0          1.0        0.0\n",
       "6432       0.0          1.0        0.0\n",
       "6433       0.0          1.0        0.0\n",
       "6434       0.0          1.0        0.0\n",
       "\n",
       "[6435 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ -2.06      ,  44.86965209,  67.15690969, 100.14      ])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means_disc.bin_edges_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different bin edges again, showing how distinct the three methods are. I think to pick the 'best' method for a particular situation/varible, it is best to check bin edges and see if they suit your criteria.\n",
    "\n",
    "Decision Trees:\n",
    "We use this method if we want the algorithm to identify the optimal number of bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.discretisation import DecisionTreeDiscretiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_X = temperature.copy()\n",
    "temperature_y = pd.DataFrame()\n",
    "temperature_y[\"target\"] = walmart[\"Weekly_Sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = DecisionTreeDiscretiser(cv=3,\n",
    "                               scoring='neg_mean_squared_error',\n",
    "                               variables=['Temperature'],\n",
    "                               regression=True, random_state=0)\n",
    "decision_tree_dataframe = disc.fit_transform(temperature_X, temperature_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>1643690.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>1641957.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>1611968.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>1409727.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>1554806.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>713173.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>733455.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>734464.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>718125.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>1.068871e+06</td>\n",
       "      <td>760281.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6435 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature      target\n",
       "0     1.068871e+06  1643690.90\n",
       "1     1.068871e+06  1641957.44\n",
       "2     1.068871e+06  1611968.17\n",
       "3     1.068871e+06  1409727.59\n",
       "4     1.068871e+06  1554806.68\n",
       "...            ...         ...\n",
       "6430  1.068871e+06   713173.95\n",
       "6431  1.068871e+06   733455.07\n",
       "6432  1.068871e+06   734464.36\n",
       "6433  1.068871e+06   718125.53\n",
       "6434  1.068871e+06   760281.43\n",
       "\n",
       "[6435 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1068871.05802707,  938067.62011457,  650155.25988506,\n",
       "        865423.98123967])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree_dataframe[\"Temperature\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Temperature': GridSearchCV(cv=3, estimator=DecisionTreeRegressor(),\n",
       "              param_grid={'max_depth': [1, 2, 3, 4]},\n",
       "              scoring='neg_mean_squared_error')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc.binner_dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unclear how the values were obtained, need to look more into this. Why does the temperature column have such high values now?\n",
    "\n",
    "Also need to implement evaluation later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models and Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "Stochastic Gradient Descent is a stochastic/probabilitic variation of gradient descent. So, what is gradient descent? Gradient descent is one of the most popular methods of model optimization. This method minimizes the loss/cost function. The idea behind this is to find an efficient way of reaching the minimum of a function. The assumption is that the cost function needs to be a differentiable convex function. \n",
    "\n",
    "The algorithm starts off by picking a value at random as a starting point. While the gradient hasn't converged / isn't 0, the algorithm will compute the slope at the random value and then go in the opposite of the direction of the gradient (down). It will update the point and repeat the steps. The way this works in machine learning is that the algorithm picks the parameters for the model at random and then modifies them in order to achieve the minimum of the given cost function. \n",
    "\n",
    "There are two parameters you can use with Gradient Descent. First one is the learning rate. This determines how far the algorithm steps when modifying the parameters for the model. The second one is convergence threshold; if the new gradient point hasn't changed more than the convergence threshold, the algorithm considers the minimum to be found and stops iterating. \n",
    "\n",
    "Sometimes, the learning rate might be too high or too small. A good indicator of a high learning rate is if the gradient is not decreasing at every step. A good indicator of a low learning rate is if the algorithm takes a long time to run. \n",
    "\n",
    "There are two issues with gradient descent:\n",
    "\n",
    "1. Calculating derivatives for the entire dataset is time consuming. \n",
    "2. Memory required is proportional to the size of the dataset.\n",
    "\n",
    "In order to avoid these issues, we use Stochastic Gradient Descent (SGD). SGD is a probabilistic approximation of gradient descent. It is an approximation because at each iteration, the algorithm calculates the gradient for one observation picked at random, instead of calculating the gradient for the entire dataset. This provides us with significant improvement, especially when the dataset contains a lot of observations. The only condition in SGD is that the expected value of the observation picked at random is a subgradient of the function. \n",
    "\n",
    "The trade-off is that the updates have a higher variance, making the convergence much harder. New variations of SGD have developed to tackle these issues, like mini-batch SGD. Instead of only taking one point, the algorithm calculates the derivative for a batch of data. Additionally, SGD is sensetive to feature scaling.\n",
    "\n",
    "With sklearn's implementation, you have to import a `SGDClassifier` or `SGDRegressor` and then set the parameters correctly in order to get the model you want. Here's the list below:\n",
    "\n",
    "For `SGDRegressor`:\n",
    "- loss=\"squared_loss\" - ordinary least squares linear regression\n",
    "- loss=\"huber\" - huber loss for robust regression\n",
    "- loss=\"epsilon_insensitive\" - linear Support Vector Regression\n",
    "\n",
    "For `SGDClassifier`:\n",
    "- loss=\"hinge\" - gives a soft-margin linear Support Vector Machine\n",
    "- loss=\"modified_huber\" - smoothed hinge loss\n",
    "- loss=\"log\" - logistic regression\n",
    "- all of the options for `SGDRegressor`. The algorithm will treat the problem like a regression problem and encodes the classes as -1 and 1. \n",
    "\n",
    "Why use this class and not the standard classes like `SVC` or `LinearRegression`? Those specific implementations in `sklearn` use different optimization techniques, not SGD. So, if you want to use SGD for a particular problem, it's only possible to do so through this class.\n",
    "\n",
    "Sources: [Medium](https://towardsdatascience.com/stochastic-gradient-descent-explained-in-real-life-predicting-your-pizzas-cooking-time-b7639d5e6a32), [Scikit-Learn](https://scikit-learn.org/stable/modules/sgd.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>uniform_cell_size</th>\n",
       "      <th>uniform_cell_shape</th>\n",
       "      <th>marginal_adhesion</th>\n",
       "      <th>single_epi_cell_size</th>\n",
       "      <th>bare_nuclei</th>\n",
       "      <th>bland_chromation</th>\n",
       "      <th>normal_nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000025</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002945</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015425</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016277</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017023</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         clump_thickness  uniform_cell_size  uniform_cell_shape  \\\n",
       "id                                                                \n",
       "1000025                5                  1                   1   \n",
       "1002945                5                  4                   4   \n",
       "1015425                3                  1                   1   \n",
       "1016277                6                  8                   8   \n",
       "1017023                4                  1                   1   \n",
       "\n",
       "         marginal_adhesion  single_epi_cell_size bare_nuclei  \\\n",
       "id                                                             \n",
       "1000025                  1                     2           1   \n",
       "1002945                  5                     7          10   \n",
       "1015425                  1                     2           2   \n",
       "1016277                  1                     3           4   \n",
       "1017023                  3                     2           1   \n",
       "\n",
       "         bland_chromation  normal_nucleoli  mitoses  class  \n",
       "id                                                          \n",
       "1000025                 3                1        1      2  \n",
       "1002945                 3                2        1      2  \n",
       "1015425                 3                1        1      2  \n",
       "1016277                 3                7        1      2  \n",
       "1017023                 3                1        1      2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"id\", \"clump_thickness\", \"uniform_cell_size\", \"uniform_cell_shape\", \"marginal_adhesion\", \"single_epi_cell_size\",\n",
    "           \"bare_nuclei\",\"bland_chromation\", \"normal_nucleoli\", \"mitoses\", \"class\"]\n",
    "cancer = pd.read_csv(\"datasets/breast-cancer-wisconsin.csv\", names=columns, index_col=0)\n",
    "cancer.replace('?',-99999, inplace=True)\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.drop(\"class\", axis=1)\n",
    "y = cancer[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the class, we are going to be using Logistic Regression, so we are going to set the loss to \"log\". Note, that this may not be the best model for this task, but I am just trying things out and want to set non-default parameters. We will play around with different learning rate parameters. Let's start off with the default - \"optimal\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(loss=\"log\", learning_rate=\"optimal\", random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above learning rate, we completed 9 iterations, let's now check the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9428571428571428"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sgd_clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check other learning rate options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(loss=\"log\", learning_rate=\"adaptive\", random_state=0, eta0=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.2, learning_rate='adaptive', loss='log', random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this learning rate method, we have more iterations. Maybe, this comes as a cost to better accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8357142857142857"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sgd_clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, even our accuracy has went down. \n",
    "\n",
    "Let's now try using the default implementation of `LogisticRegression` in `sklearn`. The default solver for this model is the Limited-memory BFGS. However, since our dataset is quite small, we will use the \"liblinear\" optimization method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32], dtype=int32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642857142857143"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = lr_clf.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! The implementation with the liblinear optimization method has performed better. It could be because the SGD is not a good optimization method for small datasets, might be more useful with larger datasets. Need to test this theory later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
