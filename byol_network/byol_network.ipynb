{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap Your Own Latent (BYOL)\n",
    "## By: Karim Zakir\n",
    "BYOL is a representation learning method. The idea behind this method is that the same image with two different augmentations has the same \"essence\" and thus should have the same or similar embeddings. This method was originally published in [this paper](https://arxiv.org/abs/2006.07733v3) in January 2020. \n",
    "\n",
    "Contrastive learning is a deep learning technique in which we try to learn representations of different objects with the goal that embeddings of similar objects will also be similar. Most contrastive learning architectures/methods require \"negative pairs\", which make constrastive learning computationally expensive. Unlike those methods, BYOL does not require negative pairs, so it's a lot more efficient!\n",
    " \n",
    "In BYOL, we start off by taking an image and applying two different augmentations on it ($t$ and $t'$). These two images are fed to two different networks called online and target. Let's first focus on the online network. After applying augmentation $t$ on a given image, we feed it into the first part of the online network, which is an encoder, which could be any network that transforms an image to features. frf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from copy import deepcopy\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_augmentation():\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomResizedCrop((224, 224)),  # interpolation should be BICUBIC, but outputs NAN for some reason\n",
    "\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "\n",
    "        transforms.RandomApply(\n",
    "            [transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)], p=0.8\n",
    "        ),\n",
    "\n",
    "        transforms.RandomApply([transforms.Grayscale(num_output_channels=3)], p=0.2),\n",
    "\n",
    "        transforms.GaussianBlur((23, 23)),\n",
    "    ])\n",
    "\n",
    "\n",
    "def target_augmentation():\n",
    "    return transforms.Compose([\n",
    "        transforms.RandomResizedCrop((224, 224)),  # interpolation should be BICUBIC, but outputs NAN for some reason\n",
    "        \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "\n",
    "        transforms.RandomApply(\n",
    "            [transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)], p=0.8\n",
    "        ),\n",
    "\n",
    "        transforms.RandomApply([transforms.Grayscale(num_output_channels=3)], p=0.2),\n",
    "\n",
    "        transforms.RandomApply([transforms.GaussianBlur((23, 23))], p=0.1),\n",
    "\n",
    "        transforms.RandomSolarize(threshold=0.5, p=0.2)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOL(nn.Module):\n",
    "\n",
    "    def __init__(self, online_augmentation, target_augmentation, encoder_model):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.online_augmentation = online_augmentation\n",
    "        self.target_augmentation = target_augmentation\n",
    "    \n",
    "        self.encoder = encoder_model\n",
    "        self.encoder.fc = nn.Identity()\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 256)\n",
    "        )\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(256, 4096),\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 256)\n",
    "        )\n",
    "\n",
    "        self.online_network = nn.Sequential(\n",
    "            self.encoder,\n",
    "            self.projector,\n",
    "            self.predictor\n",
    "        )\n",
    "\n",
    "        self.target_network = deepcopy(nn.Sequential(\n",
    "            self.encoder,\n",
    "            self.projector\n",
    "        ))\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.online_network.parameters())\n",
    "        self.tau_base = 0.996\n",
    "        self.tau = self.tau_base\n",
    "\n",
    "    def fit(self, train_loader, val_loader, epochs=1000, verbose=True):\n",
    "\n",
    "        train_loss = []\n",
    "        val_loss = []\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            \n",
    "            self.train(train_loader)\n",
    "\n",
    "            self.tau += 1 - (1 - self.tau_base) * (math.cos(math.pi*(epoch + 1) / epochs) + 1)/2\n",
    "\n",
    "            train_loss.append(self.validate(train_loader))\n",
    "            val_loss.append(self.validate(val_loader))\n",
    "            print(f\"Epoch {epoch}\")\n",
    "            print(f\"Train Loss: {train_loss}\")\n",
    "            print(f\"Validation Loss: {val_loss}\")\n",
    "        \n",
    "        return train_loss, val_loss\n",
    "\n",
    "    def train(self, train_loader):\n",
    "\n",
    "        self.online_network.train()\n",
    "        self.target_network.train()\n",
    "\n",
    "        for batch_X, batch_y in tqdm(train_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            batch_loss = self.forward(batch_X)\n",
    "\n",
    "            batch_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Update target's parameters\n",
    "            for target_param, online_param in zip(self.online_network.parameters(), self.target_network.parameters()):\n",
    "                target_param = self.tau * target_param + (1 - self.tau) * online_param\n",
    "            print(\"finished batch\")\n",
    "\n",
    "\n",
    "        self.online_network.eval()\n",
    "        self.target_network.eval()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        view = self.online_augmentation(batch)\n",
    "        view_prime = self.target_augmentation(batch)\n",
    "\n",
    "        online_output, online_output_prime = self.online_network(view), self.online_network(view_prime)\n",
    "        online_output, online_output_prime = F.normalize(online_output), F.normalize(online_output_prime)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            target_output, target_output_prime = self.target_network(view_prime), self.target_network(view)\n",
    "            target_output, target_output_prime = F.normalize(target_output), F.normalize(target_output_prime)\n",
    "\n",
    "        loss = self.loss_fn(online_output, target_output) + self.loss_fn(online_output_prime, target_output_prime)\n",
    "        return loss\n",
    "    \n",
    "    def validate(self, loader):\n",
    "        loss = 0\n",
    "        count = 0\n",
    "\n",
    "        for batch in loader:\n",
    "            with torch.no_grad():\n",
    "                loss += self.forward(batch)\n",
    "            count += len(batch)\n",
    "        \n",
    "        return loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "byol = BYOL(online_augmentation(), target_augmentation(), torchvision.models.resnet50())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_labeled = torchvision.datasets.STL10(\".\", split=\"train\", download=True, transform=transforms.ToTensor())\n",
    "train_unlabeled = torchvision.datasets.STL10(\".\", split=\"unlabeled\", download=True, transform=transforms.ToTensor())\n",
    "test_labeled = torchvision.datasets.STL10(\".\", split=\"test\", download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ll = DataLoader(train_labeled, BATCH_SIZE, shuffle=True)\n",
    "train_ul = DataLoader(train_unlabeled, BATCH_SIZE, shuffle=True)\n",
    "test_ll = DataLoader(test_labeled, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, val_loss = byol.fit(train_ul, train_ll, 1000)\n",
    "# Trained in Google Collab with a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_sup_encoder = torchvision.models.resnet50()\n",
    "semi_sup_encoder.fc = nn.Identity()\n",
    "semi_sup_encoder.load_state_dict(torch.load(\"./encoder_params.pt\", map_location=torch.device(\"cpu\")))\n",
    "semi_sup_encoder.fc = nn.Linear(2048, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0816,  0.0208, -0.1299, -0.8986, -0.2330, -0.2298,  0.3447, -0.1169,\n",
       "         1.2655,  0.5311], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_sup_encoder(torch.rand(1, 3, 128, 128))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervised:\n",
    "\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "        self.optimiser = torch.optim.Adam(self.model.parameters())\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "\n",
    "    def fit(self, train_dl, val_dl, epochs=50):\n",
    "\n",
    "        results = {\"train_acc\": [], \"val_acc\": [], \"train_loss\": [], \"val_loss\": []}\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            self.train(train_dl)\n",
    "\n",
    "            train_loss, train_acc = self.validate(train_dl)\n",
    "            val_loss, val_acc = self.validate(val_dl)\n",
    "\n",
    "            results[\"train_loss\"].append(train_loss)\n",
    "            results[\"train_acc\"].append(train_acc)\n",
    "            results[\"val_loss\"].append(val_loss)\n",
    "            results[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def train(self, train_loader):\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "\n",
    "            self.optimiser.zero_grad()\n",
    "            \n",
    "            pred = self.model(batch_X)\n",
    "            loss = self.loss_fn(pred, batch_y)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimiser.step()\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def validate(self, loader):\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in loader:\n",
    "                count += len(batch_y)\n",
    "\n",
    "                pred = self.model(batch_X)\n",
    "                class_pred = torch.argmax(pred, dim=1)\n",
    "\n",
    "                loss += self.loss_fn(pred, batch_y)\n",
    "                correct += (class_pred == batch_y).sum()\n",
    "        return loss / count, correct / count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_sup = Supervised(semi_sup_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_sup.fit(train_ll, test_ll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "836bca15fb3131664fa986416905c3f6b7c72a580a461949970047754da3200b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
