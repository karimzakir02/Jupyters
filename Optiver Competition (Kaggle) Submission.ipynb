{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optiver Competition Submission\n",
    "## By: Karim Zakir\n",
    "\n",
    "Below is my submission for the [Optiver Competition](https://www.kaggle.com/c/optiver-realized-volatility-prediction/overview) on Kaggle. The submission had a score of 0.27818 (the lower the better). This placed me 3,151st out of 3965 teams. While this is a low placement, the competition provided me with a great learning opportunity, as well as an interesting challenge! I am looking forward to learning from my mistakes and studying new concepts and scoring better on my next competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-02T20:34:31.431603Z",
     "iopub.status.busy": "2021-09-02T20:34:31.431198Z",
     "iopub.status.idle": "2021-09-02T20:34:31.449010Z",
     "shell.execute_reply": "2021-09-02T20:34:31.447666Z",
     "shell.execute_reply.started": "2021-09-02T20:34:31.431555Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "from xgboost import XGBRegressor\n",
    "import glob\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "book_train_files = glob.glob('/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet/*')\n",
    "book_test_files = glob.glob(\"/kaggle/input/optiver-realized-volatility-prediction/book_test.parquet/*\")\n",
    "\n",
    "trade_train_files = glob.glob(\"/kaggle/input/optiver-realized-volatility-prediction/trade_train.parquet/*\")\n",
    "trade_test_files = glob.glob(\"/kaggle/input/optiver-realized-volatility-prediction/trade_test.parquet/*\")\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T20:34:30.021875Z",
     "iopub.status.busy": "2021-09-02T20:34:30.021188Z",
     "iopub.status.idle": "2021-09-02T20:34:30.027018Z",
     "shell.execute_reply": "2021-09-02T20:34:30.025924Z",
     "shell.execute_reply.started": "2021-09-02T20:34:30.021836Z"
    }
   },
   "outputs": [],
   "source": [
    "book_sample_list = [\"../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0\",\n",
    "                    \"../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=1\",\n",
    "                    \"../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=10\"]\n",
    "trade_sample_list = [\"../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0\",\n",
    "                     \"../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=1\",\n",
    "                     \"../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T20:34:28.634238Z",
     "iopub.status.busy": "2021-09-02T20:34:28.633832Z",
     "iopub.status.idle": "2021-09-02T20:34:28.645168Z",
     "shell.execute_reply": "2021-09-02T20:34:28.643918Z",
     "shell.execute_reply.started": "2021-09-02T20:34:28.634200Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_submission(book_train_files, book_test_files, trade_train_files, trade_test_files):\n",
    "    model = train_model(book_train_files, trade_train_files)\n",
    "    \n",
    "    f = open(\"model.pickle\", \"wb\")\n",
    "    pickle.dump(model, f)\n",
    "    f.close()\n",
    "    \n",
    "    test_data = prepare_features_multi(book_test_files, trade_test_files, 30)\n",
    "        \n",
    "    predictions = model.predict(test_data.drop([\"row_id\"], axis=1))\n",
    "    \n",
    "    submission = pd.DataFrame(predictions, index=test_data[\"row_id\"], columns=[\"target\"]).reset_index()\n",
    "    \n",
    "    submission.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "def train_model(book_train_files, trade_train_files):\n",
    "    \n",
    "    model = XGBRegressor()\n",
    "    \n",
    "    X, y = prepare_train_data(book_train_files, trade_train_files)\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def prepare_train_data(book_data, trade_data):\n",
    "    features = prepare_features_multi(book_data, trade_data, 30)\n",
    "    \n",
    "    train = pd.read_csv(\"/kaggle/input/optiver-realized-volatility-prediction/train.csv\")\n",
    "    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "    \n",
    "    train_data = train.merge(features, on=\"row_id\")\n",
    "\n",
    "    X = train_data.drop([\"stock_id\", \"time_id\", \"row_id\", \"target\"], axis=1)\n",
    "    y = train_data[\"target\"]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T20:41:17.715813Z",
     "iopub.status.busy": "2021-09-02T20:41:17.715143Z",
     "iopub.status.idle": "2021-09-02T20:41:17.724469Z",
     "shell.execute_reply": "2021-09-02T20:41:17.723695Z",
     "shell.execute_reply.started": "2021-09-02T20:41:17.715770Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_features_multi(book_data, trade_data, modular):\n",
    "    count = 0\n",
    "    df_with_features = pd.DataFrame()\n",
    "    split = int(len(book_data) / 4) + 1\n",
    "    split_book_data = np.array_split(book_data, split)\n",
    "    split_trade_data = np.array_split(trade_data, split)\n",
    "    for book_split, trade_split in zip(split_book_data, split_trade_data):\n",
    "        with Manager() as manager:\n",
    "            result_list = manager.list()\n",
    "            processes = []\n",
    "            for book_file, trade_file in zip(book_split, trade_split):\n",
    "                p = Process(target=prepare_features, args=(book_file, trade_file, result_list, modular))\n",
    "                p.start()\n",
    "                processes.append(p)\n",
    "            for p in processes:\n",
    "                p.join()\n",
    "            result_list = list(result_list)\n",
    "            df_with_features = pd.concat([df_with_features] + result_list)\n",
    "            count += len(book_split)\n",
    "            print(count)\n",
    "    return df_with_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T19:33:33.039612Z",
     "iopub.status.busy": "2021-09-02T19:33:33.038998Z",
     "iopub.status.idle": "2021-09-02T19:33:33.043647Z",
     "shell.execute_reply": "2021-09-02T19:33:33.042333Z",
     "shell.execute_reply.started": "2021-09-02T19:33:33.039559Z"
    }
   },
   "outputs": [],
   "source": [
    "# def prepare_feature_multi(book_data, trade_data, modular):\n",
    "#     with Manager() as manager:\n",
    "#         result_list = manager.list()\n",
    "#         pool = multiprocessing.Pool(processes=5)\n",
    "#         pool.starmap(prepare_features, book_data, trade_data, result_list, modular)\n",
    "#         result_list = list(result_list)\n",
    "#         df_with_features = pd.concat(result_list)\n",
    "#         return df_with_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T20:34:34.785675Z",
     "iopub.status.busy": "2021-09-02T20:34:34.785136Z",
     "iopub.status.idle": "2021-09-02T20:34:34.818465Z",
     "shell.execute_reply": "2021-09-02T20:34:34.816623Z",
     "shell.execute_reply.started": "2021-09-02T20:34:34.785622Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_features(book_file, trade_file, result_list, modular):    \n",
    "    book_features = prepare_book_features(book_file)\n",
    "    trade_features = prepare_trade_features(trade_file)\n",
    "    combined_features = book_features.merge(trade_features, on=[\"row_id\"], how=\"outer\")\n",
    "    result_list.append(combined_features)\n",
    "\n",
    "def prepare_book_features(file_path):\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    \n",
    "    book_data = pd.read_parquet(file_path)\n",
    "    \n",
    "    book_data[\"wap1\"] = (book_data[\"bid_price1\"] * book_data[\"ask_size1\"] + book_data[\"ask_price1\"] * book_data[\"bid_size1\"]) \\\n",
    "                        / (book_data[\"bid_size1\"] + book_data[\"ask_size1\"])\n",
    "    book_data[\"wap2\"] = (book_data[\"bid_price2\"] * book_data[\"ask_size2\"] + book_data[\"ask_price2\"] * book_data[\"bid_size2\"]) \\\n",
    "                        / (book_data[\"bid_size2\"] + book_data[\"ask_size2\"])\n",
    "    book_data['log_return1'] = book_data.groupby(['time_id'])['wap1'].apply(log_return)\n",
    "    book_data[\"log_return2\"] = book_data.groupby(['time_id'])[\"wap2\"].apply(log_return)\n",
    "    book_data = book_data[~book_data[\"log_return1\"].isnull()]\n",
    "    book_data = book_data[~book_data[\"log_return2\"].isnull()]\n",
    "    book_data[\"bid_ask_spread1\"] = book_data[\"ask_price1\"] / book_data[\"bid_price1\"] - 1\n",
    "    book_data[\"bid_ask_spread2\"] = book_data[\"ask_price2\"] / book_data[\"bid_price2\"] - 1\n",
    "    book_data[\"bid_ask_ratio\"] = book_data[\"bid_size1\"] / book_data[\"ask_size1\"]\n",
    "    transposed_prices = book_data[[\"bid_price1\", \"ask_price1\", \"bid_price2\", \"ask_price2\"]].transpose()\n",
    "    book_data[\"std_price\"] = transposed_prices.std()\n",
    "    transposed_sizes = book_data[[\"bid_size1\", \"ask_size1\", \"bid_size2\", \"ask_size2\"]].transpose()\n",
    "    book_data[\"std_size\"] = transposed_sizes.std()\n",
    "    book_data[\"std_price_seconds\"] = book_data[\"std_price\"] * book_data[\"seconds_in_bucket\"]\n",
    "    book_data[\"log_return_seconds\"] = book_data[\"log_return1\"] * book_data[\"seconds_in_bucket\"]\n",
    "    book_data[\"bid_ask_spread1_seconds\"] = book_data[\"bid_ask_spread1\"] * book_data[\"seconds_in_bucket\"]\n",
    "    book_data[\"bid_1_price_size\"] = book_data[\"bid_price1\"] * book_data[\"bid_size1\"]\n",
    "    book_data[\"bid_2_price_size\"] = book_data[\"bid_price2\"] * book_data[\"bid_size2\"]\n",
    "    book_data[\"ask_1_price_size\"] = book_data[\"ask_price1\"] * book_data[\"ask_size1\"]\n",
    "    book_data[\"ask_2_price_size\"] = book_data[\"ask_price2\"] * book_data[\"ask_size2\"]\n",
    "    transposed_prices_size = book_data[[\"bid_1_price_size\", \"ask_1_price_size\", \"bid_2_price_size\", \"ask_2_price_size\"]].transpose()\n",
    "    book_data[\"prices_size_std\"] = transposed_prices.std()\n",
    "\n",
    "    groupby_dict = {\n",
    "        \"log_return1\": [\"mean\", \"std\", numeric_range, realized_volatility, time_range],\n",
    "        \"log_return2\": [\"mean\", \"std\", numeric_range, realized_volatility, time_range],\n",
    "        \"bid_ask_spread1\": [\"mean\", \"std\"],\n",
    "        \"bid_ask_spread2\": [\"mean\", \"std\"],\n",
    "        \"bid_ask_ratio\": [\"mean\", \"std\"],\n",
    "        \"std_price\": [\"mean\"],\n",
    "        \"std_size\": [\"mean\"],\n",
    "        \"std_price_seconds\": [\"mean\"],\n",
    "        \"log_return_seconds\": [\"mean\", \"std\", time_range],\n",
    "        \"bid_ask_spread1_seconds\": [time_range],\n",
    "        \"prices_size_std\": [\"mean\"]\n",
    "    }\n",
    "    \n",
    "    result_df = book_data.groupby(\"time_id\", as_index=False).agg(groupby_dict)\n",
    "    \n",
    "    result_df.columns = ['_'.join(col).strip('_') for col in result_df.columns]\n",
    "            \n",
    "    result_df[\"row_id\"] = result_df[\"time_id\"].apply(lambda time_id: f\"{stock_id}-{time_id}\")\n",
    "    \n",
    "    result_df.drop(\"time_id\", axis=1, inplace=True)\n",
    "        \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def prepare_trade_features(file_path):\n",
    "    stock_id = file_path.split(\"=\")[1]\n",
    "        \n",
    "    trade_data = pd.read_parquet(file_path)\n",
    "    trade_data[\"trade_log_return\"] = trade_data.groupby([\"time_id\"])[\"price\"].apply(log_return)\n",
    "    trade_data = trade_data[~trade_data[\"trade_log_return\"].isnull()]\n",
    "    trade_data[\"trade_log_return_seconds_interaction\"] = trade_data[\"trade_log_return\"] * trade_data[\"seconds_in_bucket\"]\n",
    "    trade_data[\"trade_log_return_size_interaction\"] = trade_data[\"trade_log_return\"] * trade_data[\"size\"]\n",
    "    trade_data[\"size_per_order\"] = trade_data[\"size\"] / trade_data[\"order_count\"]\n",
    "    trade_data[\"size_order_interaction\"] = trade_data[\"size\"] * trade_data[\"order_count\"]\n",
    "\n",
    "    groupby_dict = {\n",
    "        \"price\": [\"std\", time_range, numeric_range, \"count\"],\n",
    "        \"size\": [\"mean\", \"std\", numeric_range, \"sum\"],\n",
    "        \"trade_log_return\": [\"mean\", \"std\", numeric_range, time_range, realized_volatility],\n",
    "        \"trade_log_return_seconds_interaction\": [\"std\"],\n",
    "        \"trade_log_return_size_interaction\": [\"std\", \"mean\"],\n",
    "        \"size_per_order\": [\"mean\"],\n",
    "        \"size_order_interaction\": [\"mean\"],\n",
    "        \n",
    "    }\n",
    "        \n",
    "    result_df = trade_data.groupby(\"time_id\", as_index=False).agg(groupby_dict)\n",
    "    result_df.fillna(0, inplace=True)\n",
    "    \n",
    "    result_df.columns = ['_'.join(col).strip('_') for col in result_df.columns]\n",
    "    \n",
    "    result_df[\"row_id\"] = result_df[\"time_id\"].apply(lambda time_id: f\"{stock_id}-{time_id}\")\n",
    "    \n",
    "    result_df.drop(\"time_id\", axis=1, inplace=True)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def time_range(interaction_var):\n",
    "    return interaction_var.iloc[-1] - interaction_var.iloc[0]\n",
    "\n",
    "def numeric_range(prices):\n",
    "    return max(prices) - min(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T21:09:31.754652Z",
     "iopub.status.busy": "2021-09-02T21:09:31.754219Z",
     "iopub.status.idle": "2021-09-02T21:09:31.759215Z",
     "shell.execute_reply": "2021-09-02T21:09:31.758097Z",
     "shell.execute_reply.started": "2021-09-02T21:09:31.754610Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare_submission(book_sample_list, book_test_files, trade_sample_list, trade_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-02T20:41:22.073701Z",
     "iopub.status.busy": "2021-09-02T20:41:22.073302Z",
     "iopub.status.idle": "2021-09-02T21:07:55.799035Z",
     "shell.execute_reply": "2021-09-02T21:07:55.797939Z",
     "shell.execute_reply.started": "2021-09-02T20:41:22.073668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "8\n",
      "12\n",
      "16\n",
      "20\n",
      "24\n",
      "28\n",
      "32\n",
      "36\n",
      "40\n",
      "44\n",
      "48\n",
      "52\n",
      "56\n",
      "60\n",
      "64\n",
      "68\n",
      "72\n",
      "76\n",
      "80\n",
      "84\n",
      "88\n",
      "92\n",
      "96\n",
      "100\n",
      "103\n",
      "106\n",
      "109\n",
      "112\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "prepare_submission(book_train_files, book_test_files, trade_train_files, trade_test_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
