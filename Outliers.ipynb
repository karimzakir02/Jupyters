{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Outliers\n",
    "## By: Karim Zakir\n",
    "\n",
    "### Introduction\n",
    "Datasets can often have outliers, points which are incredibly far or unlike most of the data. There are several reasons such points can appear in the dataset. Those points could represent anomalies, unusual observations, or just data-entries. Either way, they can greatly affect the accuracy of a machine learning model or any statistical analaysis in general. As such, during data preprocessing, one of the objectives is to detect and remove all of the outliers in the dataset as possible. This can prove challenging, since every dataset has different data distributions, and outliers can often be overlooked when going through the data; thus, it is essential to know a variety of outlier detection techniques. In this notebook, we will focus on four techniques: numeric outlier technique, Cook's Distance, Mahalanobis Distance, and Density-Based Spatial Clustering of Applications with Noise (DBSCAN). These four method are quite different from each other (technically wise), and should provide us with a good toolset to detect outliers in the future. Note that all of these methods are non-parametric methods of outlier detection, since I won't make any assumptions about the distribution of the data.\n",
    "\n",
    "For this notebook, I will use the [Brazilian Houses To Rent](https://www.kaggle.com/dataset/0fc2c2957155f98e380a0e5e7db219aff29962b37b13e6ac5a569389cfe26e83/version/1) dataset obtained from Kaggle. This dataset is perfect for this notebook, since it contains data-entry errors, while also containing data which can throw off the techniques, as we will see later in the notebook. \n",
    "\n",
    "In order to understand how effective each of the methods are, we will take a closer look at the observations that were identified as outliers. \n",
    "\n",
    "In order to understand how effective each of the methods are, we will compare the accuracy of the model trained using filtered datasets to the accuracy of the model trained using the entire dataset with unfiltered outliers. The model we are going to use will be an ordinary least squares Linear Regression model from scikit-learn, since it is incredibly sensetive to outliers. Our accuracy metric is going to be mean absolute error, since it is quite appropriate for our model and dataset choices. Additionally, we will take a closer look at the observations which the methods will identify as outliers, since they will provide us with an insight into how the techniques work and allow us to asses the accuracy of the detection techniques further. \n",
    "\n",
    "Throughout this notebook, I will make certain decisions, which are not directly related to outlier detection techniques, such as feature choice. These decision are not going to be explained within this notebook; however, they are explained in the \"Working with Outliers Extras\" notebook.\n",
    "\n",
    "Let's start by importing all of the necessary libraries and taking a quick look at the dataset!\n",
    "\n",
    "**Make sure to mention that you will be removing the observations right away and then taking a closer look at them**\n",
    "**Or you could also just change your method work and stuff, maybe all of this modelling stuff is quite useless**\n",
    "**You'll be able to show off these skills in the late notebooks, maybe focus on just outliers now**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import chi2\n",
    "from sklearn.cluster import DBSCAN\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "      <th>floor</th>\n",
       "      <th>animal</th>\n",
       "      <th>furniture</th>\n",
       "      <th>hoa (R$)</th>\n",
       "      <th>rent amount (R$)</th>\n",
       "      <th>property tax (R$)</th>\n",
       "      <th>fire insurance (R$)</th>\n",
       "      <th>total (R$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>acept</td>\n",
       "      <td>furnished</td>\n",
       "      <td>2065</td>\n",
       "      <td>3300</td>\n",
       "      <td>211</td>\n",
       "      <td>42</td>\n",
       "      <td>5618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>320</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>acept</td>\n",
       "      <td>not furnished</td>\n",
       "      <td>1200</td>\n",
       "      <td>4960</td>\n",
       "      <td>1750</td>\n",
       "      <td>63</td>\n",
       "      <td>7973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Porto Alegre</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>acept</td>\n",
       "      <td>not furnished</td>\n",
       "      <td>1000</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>3841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Porto Alegre</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>acept</td>\n",
       "      <td>not furnished</td>\n",
       "      <td>270</td>\n",
       "      <td>1112</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>São Paulo</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>not acept</td>\n",
       "      <td>not furnished</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city  area  rooms  bathroom  parking spaces floor     animal  \\\n",
       "0     São Paulo    70      2         1               1     7      acept   \n",
       "1     São Paulo   320      4         4               0    20      acept   \n",
       "2  Porto Alegre    80      1         1               1     6      acept   \n",
       "3  Porto Alegre    51      2         1               0     2      acept   \n",
       "4     São Paulo    25      1         1               0     1  not acept   \n",
       "\n",
       "       furniture  hoa (R$)  rent amount (R$)  property tax (R$)  \\\n",
       "0      furnished      2065              3300                211   \n",
       "1  not furnished      1200              4960               1750   \n",
       "2  not furnished      1000              2800                  0   \n",
       "3  not furnished       270              1112                 22   \n",
       "4  not furnished         0               800                 25   \n",
       "\n",
       "   fire insurance (R$)  total (R$)  \n",
       "0                   42        5618  \n",
       "1                   63        7973  \n",
       "2                   41        3841  \n",
       "3                   17        1421  \n",
       "4                   11         836  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses = pd.read_csv(\"houses_to_rent_v2.csv\")\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model\n",
    "Our first objective during this investigation is to train a model with the unfiltered dataset and measure its accuracy using mean absolute error. This score will be our baseline score, to which we will compare our future accuracy measurements from models trained with filtered data. Additionally, when preparing the data, we will use the same imputation methods throughout the whole investigation to reduce any confounding variables.\n",
    "\n",
    "In order to stay consistent when measuring accuracy, we will first split the data into training and test data, and only modify/work on traning data, while test data will be exclu\n",
    "sively used for testing. This allows us to test the model without potential overfitting and also allows us to minimize any confounding variables during testing.\n",
    "\n",
    "For the features, we will use the following columns: city, area, rooms, bathroom, parking spaces, floor, animal, and furniture. Our target is going to be total (R$). We will not be using other columns, since they are unlikely to be available when applying the data on new apartments/houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the features/target and splitting the data\n",
    "features = [\"city\", \"area\", \"rooms\", \"bathroom\", \"parking spaces\", \"floor\", \"animal\", \"furniture\"]\n",
    "target = [\"total (R$)\"]\n",
    "X = houses[features]\n",
    "y = houses[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing categorical data with One Hot Encoding\n",
    "cat_cols = [\"city\", \"animal\", \"furniture\"]\n",
    "city_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "oh_city_train = pd.DataFrame(city_encoder.fit_transform(X_train[cat_cols]))\n",
    "oh_city_test = pd.DataFrame(city_encoder.transform(X_test[cat_cols]))\n",
    "\n",
    "oh_city_train.index = X_train.index\n",
    "oh_city_test.index = X_test.index\n",
    "\n",
    "X_train.drop(cat_cols, axis=1, inplace=True)\n",
    "X_test.drop(cat_cols, axis=1, inplace=True)\n",
    "\n",
    "X_train = X_train.merge(oh_city_train, left_index=True, right_index=True)\n",
    "X_test = X_test.merge(oh_city_test, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floor has some non-numerical values ('-'), these will be replaced by 0, since I am assuming there are no floors, and the data is not missing\n",
    "X_train.replace({\"-\": 0}, inplace=True)\n",
    "X_test.replace({\"-\": 0}, inplace=True)\n",
    "X_train[\"floor\"] = X_train[\"floor\"].astype(int)\n",
    "X_test[\"floor\"] = X_test[\"floor\"].astype(int)\n",
    "# Apart from this, there is no other potentially missing data in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2677.2151506422433"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_model = LinearRegression()\n",
    "default_model.fit(X_train, y_train)\n",
    "default_predictions = default_model.predict(X_test)\n",
    "baseline_mae = mean_absolute_error(default_predictions, y_test)\n",
    "baseline_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total (R$)    5490.487\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "houses[target].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2677.215... will be our baseline score, which we will use to compare our other models. This is a definitely suboptimal score, considering that the average of our target is 5490.487; however, the objective currently is not to create an accurate model. The objective is to improve our model by identifying and removing outliers. So, let's dive into some of the outlier detection techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Outlier Technique\n",
    "The Numeric Outlier Technique will arguably be the simplest method within this notebook. For this non-parametric method, we need to calculate the first and third quartiles, as well as the interquartile range. We then calculate the upper and lower 'bounds'. The upper bound is calculated by adding the interquartile range multipled typically by 1.5 to the third quartile. Similarly, the lower bound is calculated by subtracting the interquartile range multipled by 1.5 from the first quartile. Any point that lies below or above the lower bound and the upper bound respectively is considered an outlier. By having the interquartile range multiplier equal to 1.5, the upper and lower bounds will correspond to the upper and lower whiskers in a boxplot. Here is the formula visualized:\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://www.kdnuggets.com/wp-content/uploads/ouotlier-detection-eq1.jpg\" alt=\"Numeric Outlier Formula\">\n",
    "</p>\n",
    "\n",
    "Since this method only works on a one dimensional space, we will apply this method to each feature and target individually.\n",
    "\n",
    "To save time and processing power, we will only apply this method to a select number of columns, since it does not make sense to apply this method to the encoded columns where the values are only 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicable_cols = [\"area\", \"rooms\", \"bathroom\", \"floor\", \"total (R$)\"]\n",
    "k = 1.5\n",
    "num_out_train = X_train.merge(y_train, left_index=True, right_index=True)\n",
    "to_remove = {}\n",
    "for col in applicable_cols:\n",
    "    quantiles = num_out_train[[col]].quantile([0.25, 0.75])\n",
    "    q1 = quantiles.iloc[0, 0]\n",
    "    q3 = quantiles.iloc[1, 0]\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - k*iqr\n",
    "    upper_bound = q3 + k*iqr\n",
    "    records_to_remove = num_out_train[(num_out_train[col] > upper_bound) | (num_out_train[col] < lower_bound)].index\n",
    "    to_remove[col] = set(records_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: 1161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.47811447811448"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = set()\n",
    "for indexes in to_remove.values():\n",
    "    combined.update(indexes)\n",
    "print(\"Removed:\", len(combined))\n",
    "len(combined) / len(X_train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356.5500035298232"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_out_X_train = X_train.drop(list(combined), axis=0)\n",
    "num_out_y_train = y_train.drop(list(combined), axis=0)\n",
    "num_out_regress = LinearRegression()\n",
    "num_out_regress.fit(num_out_X_train, num_out_y_train)\n",
    "num_out_predictions = num_out_regress.predict(X_test)\n",
    "num_out_mae = mean_absolute_error(num_out_predictions ,y_test)\n",
    "num_out_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320.6651471124201"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mae - num_out_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the numeric outlier technique of outlier detection, we saw an increase in our model's performance. On average, it now estimates the value of the house better by approximately 320.67 R$. However, using this method, we have removed 1161 observations, which is about 14.5% of our training dataset. This is a sizable chunk of the training data, which could possibly mean that we have also removed valid records from the training data, since it is hard to consider almost 15% of the data to be outliers. Finally, it is worth tinkering around with the scaling factor, k, when using this technique to possibly find the most optimal value. Both of these inquiries will be looked into in more detail in the later section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Outlier In Detail\n",
    "We will begin the detailed analysis by looking closer at the records we have originally removed to see whether it would have been better to actually keep them or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_out_dropped = num_out_train.loc[list(combined)]\n",
    "custom_groups = {}\n",
    "for key, values in to_remove.items():\n",
    "    removed_obsv = num_out_dropped.loc[values]\n",
    "    custom_groups[key] = removed_obsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame([\"mean\", \"count\", \"min\", \"max\", \"std\"], columns=[\"metric\"])\n",
    "summary_table.set_index(\"metric\", inplace=True)\n",
    "for key in custom_groups.keys():\n",
    "    summary_table[key] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>floor</th>\n",
       "      <th>total (R$)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>688.397260</td>\n",
       "      <td>5.501548</td>\n",
       "      <td>7.282051</td>\n",
       "      <td>23.855814</td>\n",
       "      <td>2.014214e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>511.000000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>5.270000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>372.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.398000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46335.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>1.120000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2356.372676</td>\n",
       "      <td>0.950236</td>\n",
       "      <td>0.681813</td>\n",
       "      <td>19.384517</td>\n",
       "      <td>4.903646e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                area       rooms   bathroom       floor    total (R$)\n",
       "metric                                                               \n",
       "mean      688.397260    5.501548   7.282051   23.855814  2.014214e+04\n",
       "count     511.000000  323.000000  78.000000  215.000000  5.270000e+02\n",
       "min       372.000000    5.000000   7.000000   19.000000  1.398000e+04\n",
       "max     46335.000000   13.000000  10.000000  301.000000  1.120000e+06\n",
       "std      2356.372676    0.950236   0.681813   19.384517  4.903646e+04"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key, group in custom_groups.items():\n",
    "    summary_table.loc[\"mean\", key] = group[key].mean()\n",
    "    summary_table.loc[\"count\", key] = group[key].count()\n",
    "    summary_table.loc[\"min\", key] = group[key].min()\n",
    "    summary_table.loc[\"max\", key] = group[key].max()\n",
    "    summary_table.loc[\"std\", key] = group[key].std()\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistical summary above provides us with a good picture of whether the outliers we have removed were valid entries or not. Based on the maximum for 'area' and 'floor', we have removed some entries, whcih were most likely invalid. However, the minimum and the mean results for each of the columns possibly suggests that a majority of the entries we have removed were possibly valid entries, which should have been considered as part of the training data. This is especially the case if we look at the 'rooms' column, where the average is quite low and shows a plausible amount of rooms for a house. Based on this, we can say that most of the outliers that we have removed using the numeric outlier method were likely high-class houses, which are just not as frequent in the Brazilian house market. This suggests that we should increase the upper bound by increasing our scaling factor to include the more expensive houses within our dataset.\n",
    "\n",
    "Additionally, since the minimum values are quite high for each column, we know that the lower bound is fine and does not need to be focused on or modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Outlier Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric Outlier was an incredibly simple method for detecting outliers, where we only had to calculate the upper and lower quartiles to use this method. Definitely, one of its disadvantages was that we had to apply this method to each column individually, meaning that the feature columns and the target were not considered collectively. \n",
    "\n",
    "Using this method, we have removed a large chunk of the training dataset - approximately 15% of the training dataset. Using the statistical summary, we saw that while we have removed the 'true' outliers, which were most likely data errors, we have also removed a majority of proper data for upper-class housing, which could make our model incredibly ineffective for those kind of houses. In general, I think this was an ineffective method for this particular dataset, since we lost a big chunk of useful data, and our model is likely ineffective for an entire segment of the house market. Perhaps, this method could be more useful if the data was more evenly spread out, meaning that there were just as many high-class houses as there were middle to lower-class houses in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cook's Distance\n",
    "Cook's Distance is a really appropriate method for outlier detection in this case, since we are using Linear Regression and are attempting to improve our model by getting rid of outliers.\n",
    "\n",
    "To find Cook's distance, we will use the statsmodels library, which can automatically find Cook's distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that this is actually how you're supposed to do it\n",
    "sm_model = sm.OLS(y_train, X_train).fit()\n",
    "influence = sm_model.get_influence()\n",
    "cooks = influence.cooks_distance[0]\n",
    "cooks_df = pd.DataFrame(cooks, columns=[\"cooks\"])\n",
    "cooks_df.index = X_train.index\n",
    "X_train_cooks = X_train.merge(cooks_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooks_threshold = 4/len(X_train_cooks)\n",
    "X_train_cooks_filtered = X_train_cooks[X_train_cooks[\"cooks\"] < cooks_threshold]\n",
    "y_train_cooks_filtered = y_train.loc[X_train_cooks_filtered.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the removed observations for later analysis\n",
    "cooks_removed_X = X_train_cooks[X_train_cooks[\"cooks\"] >= cooks_threshold]\n",
    "cooks_removed_y = y_train.loc[cooks_removed_X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cooks_filtered.drop([\"cooks\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2514.7279991582222"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooks_model = LinearRegression()\n",
    "cooks_model.fit(X_train_cooks_filtered, y_train_cooks_filtered)\n",
    "cooks_predictions = cooks_model.predict(X_test)\n",
    "cooks_mae = mean_absolute_error(cooks_predictions, y_test)\n",
    "cooks_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.48715148402107"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mae - cooks_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_cooks) - len(X_train_cooks_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing just 8 observations from the training dataset using Cook's distance, we have improved the accuracy of our model by ~162.49, which is a decent increase in the performance. This result shows how sensetive linear regression is to outliers, since we only removed 8 observations. We should look at those observations in more detail...\n",
    "\n",
    "### Cook's Distance in More Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "      <th>floor</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>cooks</th>\n",
       "      <th>total (R$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>340</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023421</td>\n",
       "      <td>233200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6947</th>\n",
       "      <td>486</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>27580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>24606</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>18320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>700</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>54430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>32750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.135276</td>\n",
       "      <td>3549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>46335</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.006456</td>\n",
       "      <td>10220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.100990</td>\n",
       "      <td>1120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  rooms  bathroom  parking spaces  floor    0    1    2    3    4  \\\n",
       "6230    340      5         4               2      7  0.0  0.0  0.0  0.0  1.0   \n",
       "6947    486      8         4               6      0  0.0  0.0  0.0  0.0  1.0   \n",
       "5915  24606      5         4               4     12  0.0  0.0  0.0  0.0  1.0   \n",
       "2182    700      4         7               8      0  0.0  0.0  0.0  0.0  1.0   \n",
       "1444     42      1         1               0     10  0.0  0.0  1.0  0.0  0.0   \n",
       "2562     80      3         2               2    301  1.0  0.0  0.0  0.0  0.0   \n",
       "2397  46335      4         8               5     11  1.0  0.0  0.0  0.0  0.0   \n",
       "255     155      1         4               0      4  1.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        5    6    7    8     cooks  total (R$)  \n",
       "6230  1.0  0.0  0.0  1.0  0.023421      233200  \n",
       "6947  1.0  0.0  0.0  1.0  0.000656       27580  \n",
       "5915  1.0  0.0  0.0  1.0  0.003419       18320  \n",
       "2182  1.0  0.0  0.0  1.0  0.001899       54430  \n",
       "1444  1.0  0.0  0.0  1.0  0.000620       32750  \n",
       "2562  1.0  0.0  0.0  1.0  0.135276        3549  \n",
       "2397  1.0  0.0  1.0  0.0  1.006456       10220  \n",
       "255   0.0  1.0  0.0  1.0  2.100990     1120000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooks_removed_X.merge(cooks_removed_y, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some of these records are clearly entry errors, such as records 2562 or 2397. Additionally, using the method, we have also removed  records such as 1444 or 6947, where there is nothing outright wrong with them at first. However, since Cook's Distance considers the data collectively, we managed to spot the records where the target was too high for housing with those features. Those could be 'true' observations; however, as shown by Cook's Distance, they are incredibly unlikely and are most likely errors in data entry. This is especially useful, since I do not have much knowledge about the Brazilian house market nor are these entries immediately recognizable in a large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cook's Distance Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have not seen such an increase in performance by using Cook's Distance when compared to numeric outliers, we can be confident that the records we have removed were most-likely data entry errors. \n",
    "\n",
    "Using this dataset, we saw that Cook's Distance can be quite powerful and effective. It is especially useful if you are not knowledgable about the data or its context. The disadvantage of this method is that it is more mathematically difficult than numeric outliers method for instance. It also requires you to import the statsmodel library, but this, in my opinion, is not a significant drawback. Some might argue that since we have not seen such a large increase in the performance, this method is not that effective; however, we have only removed 8 outliers, but have still seen a relatively significant increase in the model. Furthermore, the dataset contains housing from different segments, which handicaps linear regression quite a bit, so the lack of strong performance is not necessarily the fault of Cook's Distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahalanobis Distance\n",
    "Mahalanobis Distance is another useful method for detecting outliers in multivariate data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_train = X_train.merge(y_train, left_index=True, right_index=True)\n",
    "inv_covmat = np.linalg.pinv(mahalanobis_train.cov())\n",
    "# I have used pseudo-inverse, since the np library throws a Singular Matrix error when using the standard inverse\n",
    "mean = np.mean(mahalanobis_train)\n",
    "mahalanobis_train[\"mahalanobis_distance\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, values in mahalanobis_train.iterrows():\n",
    "    values = values[0:15]\n",
    "    mahalanobis_train.loc[index, \"mahalanobis_distance\"] = mahalanobis(values, mean, inv_covmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_threshold = chi2.ppf(0.95, mahalanobis_train.shape[1] - 1)\n",
    "mahalanobis_filtered = mahalanobis_train[mahalanobis_train[\"mahalanobis_distance\"] < mahalanobis_threshold]\n",
    "mahalanobis_removed = mahalanobis_train[mahalanobis_train[\"mahalanobis_distance\"] >= mahalanobis_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2523.9343585030283"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahalanobis_X_test = mahalanobis_filtered.iloc[:,0:14]\n",
    "mahalanobis_y_test = mahalanobis_filtered.iloc[:, 14]\n",
    "mahalanobis_model = LinearRegression()\n",
    "mahalanobis_model.fit(mahalanobis_X_test, mahalanobis_y_test)\n",
    "mahalanobis_predictions = mahalanobis_model.predict(X_test)\n",
    "mahalanobis_mae = mean_absolute_error(mahalanobis_predictions, y_test)\n",
    "mahalanobis_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.280792139215"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mae - mahalanobis_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.20635934480606"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahalanobis_mae - cooks_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mahalanobis_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we have only removed 4 records; however, we still saw a substantial increase in the performance of the model. Indeed, the Cook's Distance method performed better only by ~9.21 R$ on average, despite removing 4 more records. This could suggest two things:\n",
    "- the records that we have just removed contributed to the performance significantly more than the records we haven't removed\n",
    "- we have removed different observations from the dataset\n",
    "\n",
    "We are going to investigate this in the next section\n",
    "\n",
    "### Mahalanobis's Distance In Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "      <th>floor</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>total (R$)</th>\n",
       "      <th>mahalanobis_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>24606</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18320</td>\n",
       "      <td>40.483562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3549</td>\n",
       "      <td>47.864910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>46335</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10220</td>\n",
       "      <td>76.215416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1120000</td>\n",
       "      <td>85.500535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  rooms  bathroom  parking spaces  floor    0    1    2    3    4  \\\n",
       "5915  24606      5         4               4     12  0.0  0.0  0.0  0.0  1.0   \n",
       "2562     80      3         2               2    301  1.0  0.0  0.0  0.0  0.0   \n",
       "2397  46335      4         8               5     11  1.0  0.0  0.0  0.0  0.0   \n",
       "255     155      1         4               0      4  1.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        5    6    7    8  total (R$)  mahalanobis_distance  \n",
       "5915  1.0  0.0  0.0  1.0       18320             40.483562  \n",
       "2562  1.0  0.0  0.0  1.0        3549             47.864910  \n",
       "2397  1.0  0.0  1.0  0.0       10220             76.215416  \n",
       "255   0.0  1.0  0.0  1.0     1120000             85.500535  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahalanobis_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Mahalanobis Distance removed half of the records that Cook's Distance has removed. These are the records, where data entry is quite clearly incorrect. We did not, however, remove the 4 records, which seemed fine, but were most likely incorrect or did not make sense collectively. Perhaps, if we expanded the margin those records would be included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "      <th>floor</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>total (R$)</th>\n",
       "      <th>mahalanobis_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>24606</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18320</td>\n",
       "      <td>40.483562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3549</td>\n",
       "      <td>47.864910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9241</th>\n",
       "      <td>12732</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2417</td>\n",
       "      <td>21.333782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>46335</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10220</td>\n",
       "      <td>76.215416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1120000</td>\n",
       "      <td>85.500535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  rooms  bathroom  parking spaces  floor    0    1    2    3    4  \\\n",
       "5915  24606      5         4               4     12  0.0  0.0  0.0  0.0  1.0   \n",
       "2562     80      3         2               2    301  1.0  0.0  0.0  0.0  0.0   \n",
       "9241  12732      3         2               0      3  0.0  1.0  0.0  0.0  0.0   \n",
       "2397  46335      4         8               5     11  1.0  0.0  0.0  0.0  0.0   \n",
       "255     155      1         4               0      4  1.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "        5    6    7    8  total (R$)  mahalanobis_distance  \n",
       "5915  1.0  0.0  0.0  1.0       18320             40.483562  \n",
       "2562  1.0  0.0  0.0  1.0        3549             47.864910  \n",
       "9241  1.0  0.0  0.0  1.0        2417             21.333782  \n",
       "2397  1.0  0.0  1.0  0.0       10220             76.215416  \n",
       "255   0.0  1.0  0.0  1.0     1120000             85.500535  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahalanobis_threshold_80 = chi2.ppf(0.8, mahalanobis_train.shape[1] - 1)\n",
    "mahalanobis_train_80_removed = mahalanobis_train[mahalanobis_train[\"mahalanobis_distance\"] >= mahalanobis_threshold_80]\n",
    "mahalanobis_train_80_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, although we expanded the two-tailed margin by quite a bit, we have only obtained one additional observation with the index 9241. This observation was not spotted by Cook's Distance, although it is most likely an error in data-entry, since it has incredibly huge area. This puts Cook's Distance effectiveness into question, since it has not spotted this particular outlier. We should check whether it affects the performance of the model or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2428.638517498439"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mahalanobis_train_80 = mahalanobis_train[mahalanobis_train[\"mahalanobis_distance\"] < mahalanobis_threshold_80]\n",
    "mahalanobis_X_test_80 = mahalanobis_train_80.iloc[:,0:14]\n",
    "mahalanobis_y_test_80 = mahalanobis_train_80.iloc[:, 14]\n",
    "mahalanobis_model_80 = LinearRegression()\n",
    "mahalanobis_model_80.fit(mahalanobis_X_test_80, mahalanobis_y_test_80)\n",
    "mahalanobis_predictions_80 = mahalanobis_model_80.predict(X_test)\n",
    "mahalanobis_mae_80 = mean_absolute_error(mahalanobis_predictions_80, y_test)\n",
    "mahalanobis_mae_80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, by filtering out the observation 1492, we have increased the performance of our model substantilly, despite removing only one record. Perhaps it is worth expanding the range in order to remove as many outliers as possible; however, this comes with a risk of removing valid data entries. Thus, the process will need to be monitored closely to ensure that no valid records are removed from the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis's Distance Conclusion\n",
    "Despite being a similar method to Cook's Distance, Mahalanobis's Distance is capable of detecting different outliers, as we saw previously, when we expanded the range. Additionally, we saw that, even when the range was relatively limited, the method detected the most influential outliers, making it quite effective and efficient. However, I think it is still quite important to play around with this method to ensure that all of the outliers are removed. Additionally, Mahalanobis Distance could be used in combination with Cook's Distance, since, as we saw previosuly, they can spot different outliers, which have a strong impact on the model. Also, by finding the same outliers, we gain more confidence to remove them.\n",
    "\n",
    "Finally, as stated in the previous section, it is worth playing around with this method when analyzing datasets by expanding the detection range. However, this can only work properly when you're able to check the validity of the observations yourself to ensure that no 'true' records are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN (Density Based Spatial Clustering of Applications with Noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan_train = X_train.merge(y_train, left_index=True, right_index=True)\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan.fit(dbscan_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7955"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = []\n",
    "outlier_count = 0\n",
    "for value in dbscan.labels_:\n",
    "    if value not in unique:\n",
    "        unique.append(value)\n",
    "    if value == -1:\n",
    "        outlier_count += 1\n",
    "outlier_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.20189549819179"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_count / len(X_train) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main issues with using DBSCAN is having to be careful by setting your own parameters. As you can see, if we keep the epsilon at its default value, then we get 7955 outliers, which is over 99% of our training dataset. It is not immediately clear what the epsilon value should be, so we will run an experiment to attempt to determine the best epsilon value for this dataset. We will increment the epsilon value by 0.5, starting from 0.5, and measure the MAE for new training datasets to determine the most optimal epsilon value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [i for i in np.arange(0.5, 200.5, 1)]\n",
    "mae_list = []\n",
    "removed_list = []\n",
    "for eps in eps_list:\n",
    "    dbscan = DBSCAN(eps=eps)\n",
    "    dbscan.fit(dbscan_train)\n",
    "    labels_df = pd.DataFrame(dbscan.labels_, columns=[\"labels\"])\n",
    "    labels_df.index = dbscan_train.index\n",
    "    current_copy = dbscan_train.copy()\n",
    "    current_copy = current_copy.merge(labels_df, right_index=True, left_index=True)\n",
    "    removed = len(current_copy[current_copy[\"labels\"] == -1])\n",
    "    removed_list.append(removed)\n",
    "    current_copy = current_copy[current_copy[\"labels\"] >= 0]\n",
    "    dbscan_X = current_copy.iloc[:, :14]\n",
    "    dbscan_y = current_copy.iloc[:, 14]\n",
    "    dbscan_regress = LinearRegression()\n",
    "    dbscan_regress.fit(dbscan_X, dbscan_y)\n",
    "    dbscan_predictions = dbscan_regress.predict(X_test)\n",
    "    dbscan_mae = mean_absolute_error(dbscan_predictions, y_test)\n",
    "    mae_list.append(dbscan_mae)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Amount of Observations Removed'}>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,8))\n",
    "fig.suptitle(\"DBSCAN Testing\")\n",
    "ax[0].set_title(\"Linear Regression MAE\")\n",
    "ax[1].set_title(\"Amount of Observations Removed\")\n",
    "sns.lineplot(x=eps_list, y=mae_list, ax=ax[0])\n",
    "sns.scatterplot(x=eps_list, y=removed_list, ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the plots above, when we begin to increase the epsilon value, the model's MAE begins to decrease rapdily, until it levels off at around 50, and begins to increase after 60. The amount of observations that we remove also rapdily decreases and continues to do so as we increase our epsilon value. \n",
    "\n",
    "Interestingly, this method has removed the most observations from the record. At its lowest MAE, DBSCAN has deemed just less than 1000 observations as outliers, a lot more than what we got using Cook's Distance or Mahalanobis's Distance. This doesn't necessarily suggest that these observations were outliers. It is best to look into these observations in more detail in order to understand why the algorithm classified them as outliers.\n",
    "\n",
    "### DBSCAN In More Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 50.5\n",
    "dbscan_50 = DBSCAN(eps=eps)\n",
    "dbscan_50.fit(dbscan_train)\n",
    "labels_df_50 = pd.DataFrame(dbscan_50.labels_, columns=[\"labels\"])\n",
    "labels_df_50.index = dbscan_train.index\n",
    "outliers_index = labels_df_50[labels_df_50[\"labels\"] == -1].index\n",
    "outliers_dbscan = dbscan_train.loc[outliers_index]\n",
    "len(outliers_dbscan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large amount of observations removed, we will instead look at the summary statistics for these observations, as well as a few samples from the removed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "      <th>floor</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>total (R$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1.027000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>459.561831</td>\n",
       "      <td>3.766310</td>\n",
       "      <td>4.145083</td>\n",
       "      <td>3.579357</td>\n",
       "      <td>5.388510</td>\n",
       "      <td>0.133398</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>0.043817</td>\n",
       "      <td>0.081792</td>\n",
       "      <td>0.693281</td>\n",
       "      <td>0.843233</td>\n",
       "      <td>0.156767</td>\n",
       "      <td>0.327167</td>\n",
       "      <td>0.672833</td>\n",
       "      <td>1.439482e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1677.794661</td>\n",
       "      <td>1.173918</td>\n",
       "      <td>1.529879</td>\n",
       "      <td>1.951728</td>\n",
       "      <td>11.316809</td>\n",
       "      <td>0.340170</td>\n",
       "      <td>0.213260</td>\n",
       "      <td>0.204787</td>\n",
       "      <td>0.274181</td>\n",
       "      <td>0.461356</td>\n",
       "      <td>0.363758</td>\n",
       "      <td>0.363758</td>\n",
       "      <td>0.469407</td>\n",
       "      <td>0.469407</td>\n",
       "      <td>3.565462e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.532500e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.327000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>470.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.676000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46335.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.120000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               area        rooms     bathroom  parking spaces        floor  \\\n",
       "count   1027.000000  1027.000000  1027.000000     1027.000000  1027.000000   \n",
       "mean     459.561831     3.766310     4.145083        3.579357     5.388510   \n",
       "std     1677.794661     1.173918     1.529879        1.951728    11.316809   \n",
       "min       30.000000     1.000000     1.000000        0.000000     0.000000   \n",
       "25%      254.000000     3.000000     3.000000        2.000000     0.000000   \n",
       "50%      350.000000     4.000000     4.000000        4.000000     2.000000   \n",
       "75%      470.000000     4.000000     5.000000        5.000000     9.000000   \n",
       "max    46335.000000    13.000000    10.000000       12.000000   301.000000   \n",
       "\n",
       "                 0            1            2            3            4  \\\n",
       "count  1027.000000  1027.000000  1027.000000  1027.000000  1027.000000   \n",
       "mean      0.133398     0.047712     0.043817     0.081792     0.693281   \n",
       "std       0.340170     0.213260     0.204787     0.274181     0.461356   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                 5            6            7            8    total (R$)  \n",
       "count  1027.000000  1027.000000  1027.000000  1027.000000  1.027000e+03  \n",
       "mean      0.843233     0.156767     0.327167     0.672833  1.439482e+04  \n",
       "std       0.363758     0.363758     0.469407     0.469407  3.565462e+04  \n",
       "min       0.000000     0.000000     0.000000     0.000000  9.000000e+02  \n",
       "25%       1.000000     0.000000     0.000000     0.000000  9.532500e+03  \n",
       "50%       1.000000     0.000000     0.000000     1.000000  1.327000e+04  \n",
       "75%       1.000000     0.000000     1.000000     1.000000  1.676000e+04  \n",
       "max       1.000000     1.000000     1.000000     1.000000  1.120000e+06  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_dbscan.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident by the maximum values, DBSCAN spotted the outliers that (most-likely) contain data error entries. However, it has also removed some records that we have never seen before, such as the observation with the value 30 in its area column. Let's consider this observation in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "      <th>floor</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>total (R$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7448</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  rooms  bathroom  parking spaces  floor    0    1    2    3    4  \\\n",
       "7448    30      4         4               2      0  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "        5    6    7    8  total (R$)  \n",
       "7448  1.0  0.0  1.0  0.0        9323  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_dbscan[outliers_dbscan[\"area\"] == 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be honest, it is not immediately clear whether this record is an outlier or not. It was probably removed, due to its unusually low area, considering the price and the amount of rooms in this particular house. However, it is hard to be sure whether this is a data-error entry or a 'true' record. Either way, it could be considered an outlier, since this is a highly unusual record. Let's now consider a couple of other samples from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>parking spaces</th>\n",
       "      <th>floor</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>total (R$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>280</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>350</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9368</th>\n",
       "      <td>800</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9457</th>\n",
       "      <td>292</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3564</th>\n",
       "      <td>220</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8858</th>\n",
       "      <td>800</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>360</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10690</th>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319</th>\n",
       "      <td>268</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9459</th>\n",
       "      <td>420</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>350</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  rooms  bathroom  parking spaces  floor    0    1    2    3    4  \\\n",
       "595     900      3         5               8      0  0.0  0.0  0.0  0.0  1.0   \n",
       "653     280      3         2               2     10  0.0  0.0  0.0  1.0  0.0   \n",
       "428     350      4         5               5     17  0.0  0.0  0.0  0.0  1.0   \n",
       "9368    800      5         7               6      0  0.0  0.0  0.0  0.0  1.0   \n",
       "9457    292      4         3               3      8  0.0  0.0  0.0  0.0  1.0   \n",
       "3564    220      4         3               4      4  0.0  0.0  0.0  0.0  1.0   \n",
       "8858    800      4         7               8      0  0.0  0.0  0.0  0.0  1.0   \n",
       "6727    360      4         5               5     20  0.0  0.0  0.0  0.0  1.0   \n",
       "10690   120      2         2               2      8  0.0  0.0  0.0  1.0  0.0   \n",
       "2493    300      5         3               6      0  1.0  0.0  0.0  0.0  0.0   \n",
       "5319    268      4         4               4      3  0.0  0.0  0.0  0.0  1.0   \n",
       "9459    420      4         5               0      0  0.0  0.0  0.0  0.0  1.0   \n",
       "1285    350      3         4               4      0  0.0  0.0  1.0  0.0  0.0   \n",
       "4102    400      5         3               6      0  0.0  0.0  0.0  0.0  1.0   \n",
       "4563    512      4         6               5      8  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "         5    6    7    8  total (R$)  \n",
       "595    1.0  0.0  0.0  1.0       10370  \n",
       "653    1.0  0.0  1.0  0.0       12370  \n",
       "428    1.0  0.0  1.0  0.0       19990  \n",
       "9368   1.0  0.0  0.0  1.0       17280  \n",
       "9457   1.0  0.0  1.0  0.0       15030  \n",
       "3564   1.0  0.0  0.0  1.0       15340  \n",
       "8858   0.0  1.0  0.0  1.0       18840  \n",
       "6727   1.0  0.0  0.0  1.0       16690  \n",
       "10690  1.0  0.0  1.0  0.0       14020  \n",
       "2493   1.0  0.0  0.0  1.0        5620  \n",
       "5319   1.0  0.0  1.0  0.0       10290  \n",
       "9459   1.0  0.0  0.0  1.0        8038  \n",
       "1285   0.0  1.0  0.0  1.0        3730  \n",
       "4102   1.0  0.0  0.0  1.0       16040  \n",
       "4563   1.0  0.0  1.0  0.0       14140  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_dbscan.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, we cannot immediately tell from these observations whether they are errors in data-entry, or whether they are accurate observations. Indeed, we cannot be confident whether they can be considered to be 'unusual' observations, as these make up approximately 12.5% of the training data. Perhaps, we need to increase the epsilon, and perhaps decrease the min_samples parameter to ensure we only get the most unusual points.\n",
    "\n",
    "**Increase the epsilon, reduce the min_samples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
